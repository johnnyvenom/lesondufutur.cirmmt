Session interactive 1: FR > EN

This interactive session will outline the potential of wearable computing, specifically electronic garments, as an inherently intuitive interface for the creation of soundscapes using a "peripheral" style of interaction. We argue that garments offer an ideal model for the study of interactions that seamlessly shift between the focus and the periphery of awareness, based on the long history of clothing as an interface through which we navigate the world. Given the varied intensities of sensory stimulus perceived on the human body, garments provide the potential for embedding interaction in more central as well as more peripheral areas, with varying sensory attributes of stimulus: modality, intensity, location, and duration. In addition, human beings have historically developed the expertise to wear cumbersome, high performance, or domain specific clothing necessary in the performance of highly specialized tasks (such as undersea diving, running a marathon, or playing an instrument), and focusing fully on those tasks while the clothing remains in the background or periphery of awareness. We present several XS Labs electronic garments and the ways that they engage with sound-making. We will bring an assortment of electronic textile samples and interactive garments to discuss technical implementations and brainstorm possible future projects and collaborations.

---

Keynote 5: FR > EN

Producing sound for interactive media, such as video games, is quite different from producing sound for films and other traditional linear media. The timing of events is fixed and known with the latter, whereas it is mostly unpredictable with the former. Interactive audio artists must create content in pieces, out of context, and this content is played back and put together in real-time by the game engine. Although tools have come a long way since artists would hand over wave file names to programmers in a huge Excel sheet to hook up in the game later on, they are still very imperfect.


Tools of the future should allow artists to produce auditory experiences that achieve the same level of quality and polish as what is done in traditional media, regardless of how events actually unfold in the real-time simulation. We propose to support this end goal with the three following pillars:

1. Nothing is pre-rendered, everything is interactive
2. Simulation is rendered to audio accurately by default
3. All creative decisions can take effect in real-time

In this presentation, I will review a few areas of research in interactive audio, and will discuss their challenges in the context of the above pillars. Doing so, I hope I can also give you a quick glimpse of the world of game audio.

